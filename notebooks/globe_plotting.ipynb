{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import karman\n",
    "from karman.nn import *\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "from torch import nn\n",
    "import argparse\n",
    "from pyfiglet import Figlet\n",
    "from termcolor import colored\n",
    "from dataclasses import dataclass\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.display import Image\n",
    "from astropy.time import Time\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class Opt():\n",
    "    x: 1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Karman Model Evaluation')\n",
    "\n",
    "f = Figlet(font='5lineoblique')\n",
    "print(colored(f.renderText('KARMAN'), 'red'))\n",
    "\n",
    "f = Figlet(font='digital')\n",
    "print(colored(f.renderText(\"Thermospheric  density  calculations\"), 'blue'))\n",
    "print(colored(f'Version {karman.__version__}\\n','blue'))\n",
    "opt = Opt(x=1)\n",
    "opt.model_name = 'no_lag'\n",
    "opt.model_folder = '/home/jupyter/karman-project/experiment_no_lag'\n",
    "opt.batch_size = 512\n",
    "opt.num_workers = 30\n",
    "opt.data_directory = '/home/jupyter/karman-project/data_directory'\n",
    "\n",
    "#Stick to this convention 'best_model' is the model of interest.\n",
    "model_path = [os.path.join(opt.model_folder, f) for f in os.listdir(opt.model_folder) if 'best_model' in f][0]\n",
    "\n",
    "print('Loading Data')\n",
    "model_opt=torch.load(model_path)['opt']\n",
    "\n",
    "dataset = karman.ThermosphericDensityDataset(\n",
    "    directory=opt.data_directory,\n",
    "    exclude_omni=model_opt.exclude_omni,\n",
    "    exclude_fism2_daily=model_opt.exclude_fism2_daily,\n",
    "    exclude_fism2_flare=model_opt.exclude_fism2_flare,\n",
    "    lag_minutes_omni=model_opt.lag_minutes_omni,\n",
    "    lag_days_fism2_daily=model_opt.lag_days_fism2_daily,\n",
    "    lag_minutes_fism2_flare=model_opt.lag_minutes_fism2_flare,\n",
    "    wavelength_bands_to_skip=model_opt.wavelength_bands_to_skip,\n",
    "    omniweb_downsampling_ratio=model_opt.omniweb_downsampling_ratio,\n",
    "    features_to_exclude_omni=model_opt.features_to_exclude_omni,\n",
    "    features_to_exclude_thermo=model_opt.features_to_exclude_thermo,\n",
    "    features_to_exclude_fism2_flare=model_opt.features_to_exclude_fism2_flare,\n",
    "    features_to_exclude_fism2_daily=model_opt.features_to_exclude_fism2_daily\n",
    ")\n",
    "\n",
    "print('Loading Model')\n",
    "\n",
    "if model_opt.model == 'FeedForwardDensityPredictor':\n",
    "    # Will only use an FFNN with just the thermo static features data\n",
    "    model = FeedForwardDensityPredictor(\n",
    "                        num_features=dataset.data_thermo_matrix.shape[1]\n",
    "                        )\n",
    "elif model_opt.model=='Fism2FlareDensityPredictor':\n",
    "    if model_opt.exclude_fism2_daily and model_opt.exclude_omni:\n",
    "        model=Fism2FlareDensityPredictor(\n",
    "                        input_size_thermo=dataset.data_thermo_matrix.shape[1],\n",
    "                        input_size_fism2_flare=dataset.fism2_flare_irradiance_matrix.shape[1],\n",
    "                        output_size_fism2_flare=20\n",
    "                        )\n",
    "    else:\n",
    "        raise RuntimeError(f\"exclude_fism2_daily and exclude_omni are not set to True; while model chosen is {model_opt.model}\")\n",
    "elif model_opt.model=='Fism2DailyDensityPredictor':\n",
    "    if model_opt.exclude_fism2_flare and model_opt.exclude_omni:\n",
    "        model=Fism2DailyDensityPredictor(\n",
    "                        input_size_thermo=dataset.data_thermo_matrix.shape[1],\n",
    "                        input_size_fism2_daily=dataset.fism2_daily_irradiance_matrix.shape[1],\n",
    "                        output_size_fism2_daily=20\n",
    "                        )\n",
    "    else:\n",
    "        raise RuntimeError(f\"exclude_fism2_flare and exclude_omni are not set to True; while model chosen is {model_opt.model}\")\n",
    "elif model_opt.model=='OmniDensityPredictor':\n",
    "    if model_opt.exclude_fism2_daily and model_opt.exclude_fism2_flare:\n",
    "        model=OmniDensityPredictor(\n",
    "                        input_size_thermo=dataset.data_thermo_matrix.shape[1],\n",
    "                        input_size_omni=dataset.data_omni_matrix.shape[1],\n",
    "                        output_size_omni=20\n",
    "                        )\n",
    "    else:\n",
    "        raise RuntimeError(f\"exclude_fism2_daily and exclude_fism2_flare are not set to True; while model chosen is {model_opt.model}\")\n",
    "elif model_opt.model == 'FullFeatureDensityPredictor':\n",
    "    if model_opt.exclude_omni==False and model_opt.exclude_fism2_flare==False and model_opt.exclude_fism2_daily==False:\n",
    "        model = FullFeatureDensityPredictor(\n",
    "                        input_size_thermo=dataset.data_thermo_matrix.shape[1],\n",
    "                        input_size_fism2_flare=dataset.fism2_flare_irradiance_matrix.shape[1],\n",
    "                        input_size_fism2_daily=dataset.fism2_daily_irradiance_matrix.shape[1],\n",
    "                        input_size_omni=dataset.data_omni_matrix.shape[1],\n",
    "                        output_size_fism2_flare=20,\n",
    "                        output_size_fism2_daily=20,\n",
    "                        output_size_omni=20\n",
    "                        )\n",
    "state_dict = torch.load(os.path.join(model_path))['state_dict']\n",
    "#Sanitize state_dict key names\n",
    "for key in list(state_dict.keys()):\n",
    "    if key.startswith('module'):\n",
    "    # Model was saved as dataparallel model\n",
    "        # Remove 'module.' from start of key\n",
    "        state_dict[key[7:]] = state_dict.pop(key)\n",
    "    else:\n",
    "        continue\n",
    "model.load_state_dict(state_dict)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(os.path.join(opt.data_directory, \"test_indices.txt\"), 'r') as f:\n",
    "    test_indices = [int(line.rstrip()) for line in f]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch = dataset.__getitem__(test_indices[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch['static_features']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.data_thermo.loc[dataset.index_list[test_indices[0]]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.data_thermo['all__seconds_in_day__[s]'].max()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "year = 2009\n",
    "day = 109\n",
    "second_in_day = 46935\n",
    "lon = -36.9556\n",
    "lat = 60\n",
    "date = pd.to_datetime(f'{year}/{str(day).zfill(3)}', format='%Y/%j') + pd.Timedelta(seconds=second_in_day)\n",
    "t=Time(str(date),location=(str(float(lon))+'d',str(float(lat))+'d'))\n",
    "sunpos=astropy.coordinates.get_sun(t)\n",
    "print(sunpos.ra.rad)\n",
    "print(sunpos.dec.rad)\n",
    "print(t.sidereal_time('mean').rad)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "asc_min = dataset.data_thermo['all__sun_right_ascension__[rad]'].min()\n",
    "asc_max = dataset.data_thermo['all__sun_right_ascension__[rad]'].max()\n",
    "\n",
    "decl_min = dataset.data_thermo['all__sun_declination__[rad]'].min()\n",
    "decl_max = dataset.data_thermo['all__sun_declination__[rad]'].max()\n",
    "\n",
    "sidereal_min = dataset.data_thermo['all__sidereal_time__[rad]'].min()\n",
    "sidereal_max = dataset.data_thermo['all__sidereal_time__[rad]'].max()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for key in batch.keys():\n",
    "    batch[key] = batch[key].unsqueeze(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import astropy\n",
    "images = []\n",
    "year=2009\n",
    "for day_of_year in range(109,110):\n",
    "    for time_of_day in tqdm(range(0, (24*60*60), 1200)):\n",
    "        thermo_map = np.zeros((60, 120))\n",
    "        date = pd.to_datetime(f'{year}/{str(day_of_year).zfill(3)}', format='%Y/%j') + pd.Timedelta(seconds=time_of_day)\n",
    "        str_date = str(date)\n",
    "        for lon in range(-180,180,3):\n",
    "            # doesnt appear these are dependent on latitude so I can leave them on the same lat as they take forever\n",
    "            t=Time(str_date,location=(f'{lon}d', f'0d'))\n",
    "            sunpos=astropy.coordinates.get_sun(t)\n",
    "            sun_ra=sunpos.ra.rad\n",
    "            sun_dec=sunpos.dec.rad\n",
    "            side_real = t.sidereal_time('mean').rad\n",
    "            new_batch = {}\n",
    "            new_batch['static_features'] = torch.cat(60*[batch['static_features']])\n",
    "            for key in batch.keys():\n",
    "                if key != 'static_features':\n",
    "                    new_batch[key] = torch.cat(60*[batch[key]])\n",
    "            for i, lat in enumerate(range(-90,90,3)):\n",
    "                # Maybe weheer there is more training point\n",
    "                new_batch['static_features'][i,3] = 0.5\n",
    "                new_batch['static_features'][i,2] = time_of_day/(24*60*60)\n",
    "                new_batch['static_features'][i,4] = float((lon +180)/360)\n",
    "                new_batch['static_features'][i,5] = float((lat +90)/360)\n",
    "                lst=(((time_of_day)/3600.) + (lon)/15.)/(36)\n",
    "                new_batch['static_features'][i,6] = lst\n",
    "                new_batch['static_features'][i,0] = day_of_year/366.\n",
    "\n",
    "                new_batch['static_features'][i,17] = (sun_ra - asc_min)/(asc_max-asc_min)\n",
    "                new_batch['static_features'][i,18] = (sun_dec - decl_min)/(decl_max-decl_min)\n",
    "                new_batch['static_features'][i,19] = (side_real - sidereal_min)/(sidereal_max-sidereal_min)\n",
    "            with torch.no_grad():\n",
    "                output = model.forward(new_batch)\n",
    "            thermo_map[:, int((lon+180)/3)] = np.squeeze(output.detach().cpu().numpy())\n",
    "        images.append(thermo_map)\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    plt.imshow(image, vmin=0.75, vmax=0.81)\n",
    "    plt.savefig('/home/jupyter/'+str(i)+'.png')\n",
    "\n",
    "with imageio.get_writer('day.gif', mode='I') as writer:\n",
    "    for filename in ['/home/jupyter/'+str(i)+'.png' for i in range(len(images))]:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "Image(filename=\"day.gif\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for image in images:\n",
    "    print(image.min(), image.max())"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.12 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}