{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be9bb1e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb39841d-b58f-405a-9b09-37f5eba8c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import karman\n",
    "import os\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5be08",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "\n",
    "In this case, we show how to load a dataset that contains NRLMSISE-00 and JB-08 inputs (latitude, longitude, altitude, corresponding thermospheric density, for GRACE, GOCE, SWARM-A, SWARM-B, CHAMP satellites, F10.7, Y10.7, M10.7, S10.7 Proxies, Ap indices, temperature changes due to Dst, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "455d7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path='/'+os.getcwd().strip('docs/source/tutorials')\n",
    "#we first load the scalers used in training\n",
    "with open(os.path.join(base_path,\"tests/data/thermo_scaler.pickle\"), 'rb') as handle:\n",
    "    thermo_scaler = pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(base_path,\"tests/data/cyclical_feature_scaler.pickle\"), 'rb') as handle:\n",
    "    cyclical_feature_scaler = pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(base_path,\"tests/data/thermospheric_density_scaler.pickle\"), 'rb') as handle:\n",
    "    thermospheric_density_scaler = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee7fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating thermospheric density dataset\n",
      "Creating cyclical features\n",
      "['all__dates_datetime__', 'tudelft_thermo__ground_truth_thermospheric_density__[kg/m**3]', 'tudelft_thermo__satellite__', 'celestrack__ap_h_0__', 'celestrack__ap_h_1__', 'celestrack__ap_h_2__', 'celestrack__ap_h_3__', 'celestrack__ap_h_4__', 'celestrack__ap_h_5__', 'celestrack__ap_h_6__', 'celestrack__ap_average__', 'JB08__thermospheric_density__[kg/m**3]', 'NRLMSISE00__thermospheric_density__[kg/m**3]']\n",
      "['all__day_of_year__[d]', 'all__seconds_in_day__[s]', 'all__sun_right_ascension__[rad]', 'all__sun_declination__[rad]', 'all__sidereal_time__[rad]', 'tudelft_thermo__longitude__[deg]', 'tudelft_thermo__local_solar_time__[h]']\n",
      "Used features: Index(['all__year__[y]', 'tudelft_thermo__altitude__[m]',\n",
      "       'tudelft_thermo__latitude__[deg]',\n",
      "       'space_environment_technologies__f107_average__',\n",
      "       'space_environment_technologies__f107_obs__',\n",
      "       'space_environment_technologies__s107_obs__',\n",
      "       'space_environment_technologies__s107_average__',\n",
      "       'space_environment_technologies__m107_obs__',\n",
      "       'space_environment_technologies__m107_average__',\n",
      "       'space_environment_technologies__y107_obs__',\n",
      "       'space_environment_technologies__y107_average__', 'JB08__d_st_dt__[K]',\n",
      "       'all__day_of_year__[d]_sin', 'all__day_of_year__[d]_cos',\n",
      "       'all__seconds_in_day__[s]_sin', 'all__seconds_in_day__[s]_cos',\n",
      "       'all__sun_right_ascension__[rad]_sin',\n",
      "       'all__sun_right_ascension__[rad]_cos',\n",
      "       'all__sun_declination__[rad]_sin', 'all__sun_declination__[rad]_cos',\n",
      "       'all__sidereal_time__[rad]_sin', 'all__sidereal_time__[rad]_cos',\n",
      "       'tudelft_thermo__longitude__[deg]_sin',\n",
      "       'tudelft_thermo__longitude__[deg]_cos',\n",
      "       'tudelft_thermo__local_solar_time__[h]_sin',\n",
      "       'tudelft_thermo__local_solar_time__[h]_cos'],\n",
      "      dtype='object')\n",
      "\n",
      "Finished Creating dataset.\n"
     ]
    }
   ],
   "source": [
    "#we store the features to exclude (not used in training):\n",
    "#we exclude Ap because we trained an ML model using only JB-08 inputs\n",
    "features_to_exclude_thermo=['all__dates_datetime__',\n",
    "                            'tudelft_thermo__ground_truth_thermospheric_density__[kg/m**3]',\n",
    "                            'tudelft_thermo__satellite__',\n",
    "                            'celestrack__ap_h_0__',\n",
    "                            'celestrack__ap_h_1__',\n",
    "                            'celestrack__ap_h_2__',\n",
    "                            'celestrack__ap_h_3__',\n",
    "                            'celestrack__ap_h_4__',\n",
    "                            'celestrack__ap_h_5__',\n",
    "                            'celestrack__ap_h_6__',\n",
    "                            'celestrack__ap_average__',\n",
    "                            'JB08__thermospheric_density__[kg/m**3]',\n",
    "                            'NRLMSISE00__thermospheric_density__[kg/m**3]']\n",
    "#we now load the dataset:\n",
    "dataset=karman.ThermosphericDensityDataset(\n",
    "    directory=os.path.join(base_path,'tests/data/'),\n",
    "    features_to_exclude_thermo=features_to_exclude_thermo,\n",
    "    create_cyclical_features=True,\n",
    "    max_altitude=600000,\n",
    "    thermo_scaler=thermo_scaler,\n",
    "    cyclical_feature_scaler=cyclical_feature_scaler,\n",
    "    thermospheric_density_scaler=thermospheric_density_scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3656c",
   "metadata": {},
   "source": [
    "## Loading Karman-ML Thermospheric Density Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "067c1e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we now load the Karman ML trained model:\n",
    "model_path=os.path.join(base_path,\"tests/data/kml_model\")\n",
    "print('Loading Model')\n",
    "\n",
    "model = karman.nn.SimpleNN().to(dtype=torch.float64)\n",
    "\n",
    "state_dict = torch.load(os.path.join(model_path),map_location=torch.device('cpu'))['state_dict']\n",
    "#Sanitize state_dict key names\n",
    "for key in list(state_dict.keys()):\n",
    "    if key.startswith('module'):\n",
    "    # Model was saved as dataparallel model\n",
    "        # Remove 'module.' from start of key\n",
    "        state_dict[key[7:]] = state_dict.pop(key)\n",
    "    else:\n",
    "        continue\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6a282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123696eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f6e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
